// This file was auto-generated by Fern from our API Definition.

import type { BaseClientOptions, BaseRequestOptions } from "../../../../BaseClient.js";
import { type NormalizedClientOptionsWithAuth, normalizeClientOptionsWithAuth } from "../../../../BaseClient.js";
import { mergeHeaders } from "../../../../core/headers.js";
import * as core from "../../../../core/index.js";
import * as environments from "../../../../environments.js";
import { handleNonStatusCodeError } from "../../../../errors/handleNonStatusCodeError.js";
import * as errors from "../../../../errors/index.js";
import * as Speechall from "../../../index.js";

export declare namespace SpeechToTextClient {
    export type Options = BaseClientOptions;

    export interface RequestOptions extends BaseRequestOptions {
    }
}

/**
 * Primary endpoints for converting audio streams or files into text transcripts.
 */
export class SpeechToTextClient {
    protected readonly _options: NormalizedClientOptionsWithAuth<SpeechToTextClient.Options>;

    constructor(options: SpeechToTextClient.Options) {


                        this._options = normalizeClientOptionsWithAuth(options);
                    
    }

    /**
     * This endpoint allows you to send raw audio data in the request body for transcription.
     * You can specify the desired model, language, output format, and various provider-specific features using query parameters.
     * Suitable for transcribing local audio files.
     *
     * @param {core.file.Uploadable} uploadable
     * @param {Speechall.TranscribeRequest} request
     * @param {SpeechToTextClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link Speechall.BadRequestError}
     * @throws {@link Speechall.UnauthorizedError}
     * @throws {@link Speechall.PaymentRequiredError}
     * @throws {@link Speechall.NotFoundError}
     * @throws {@link Speechall.TooManyRequestsError}
     * @throws {@link Speechall.InternalServerError}
     * @throws {@link Speechall.ServiceUnavailableError}
     * @throws {@link Speechall.GatewayTimeoutError}
     */
    public transcribe(uploadable: core.file.Uploadable, request: Speechall.TranscribeRequest, requestOptions?: SpeechToTextClient.RequestOptions): core.HttpResponsePromise<Speechall.TranscriptionResponse> {
        return core.HttpResponsePromise.fromPromise(this.__transcribe(uploadable, request, requestOptions));
    }

    private async __transcribe(uploadable: core.file.Uploadable, request: Speechall.TranscribeRequest, requestOptions?: SpeechToTextClient.RequestOptions): Promise<core.WithRawResponse<Speechall.TranscriptionResponse>> {
        const _queryParams: Record<string, string | string[] | object | object[] | null> = {};
        _queryParams.model = request.model;
        if (request.language != null) {
            _queryParams.language = request.language;
        }

        if (request.output_format != null) {
            _queryParams.output_format = request.output_format;
        }

        if (request.ruleset_id != null) {
            _queryParams.ruleset_id = request.ruleset_id;
        }

        if (request.punctuation != null) {
            _queryParams.punctuation = request.punctuation.toString();
        }

        if (request.timestamp_granularity != null) {
            _queryParams.timestamp_granularity = request.timestamp_granularity;
        }

        if (request.diarization != null) {
            _queryParams.diarization = request.diarization.toString();
        }

        if (request.initial_prompt != null) {
            _queryParams.initial_prompt = request.initial_prompt;
        }

        if (request.temperature != null) {
            _queryParams.temperature = request.temperature.toString();
        }

        if (request.smart_format != null) {
            _queryParams.smart_format = request.smart_format.toString();
        }

        if (request.speakers_expected != null) {
            _queryParams.speakers_expected = request.speakers_expected.toString();
        }

        if (request.custom_vocabulary != null) {
            if (Array.isArray(request.custom_vocabulary)) {
                _queryParams.custom_vocabulary = request.custom_vocabulary.map(item => item);
            }
            else {
                _queryParams.custom_vocabulary = request.custom_vocabulary;
            }
        }

        const _binaryUploadRequest = await core.file.toBinaryUploadRequest(uploadable);
        const _authRequest: core.AuthRequest = await this._options.authProvider.getAuthRequest();
        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(_authRequest.headers, this._options?.headers, _binaryUploadRequest.headers, requestOptions?.headers);
        const _response = await core.fetcher({
            url: core.url.join(await core.Supplier.get(this._options.baseUrl) ?? (await core.Supplier.get(this._options.environment) ?? environments.SpeechallEnvironment.Default), "transcribe"),
            method: "POST",
            headers: _headers,
            contentType: "audio/*",
            queryParameters: { ..._queryParams, ...requestOptions?.queryParams },
            requestType: "bytes",
            duplex: "half",
            body: _binaryUploadRequest.body,
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 60) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging
        });
        if (_response.ok) {
            return { data: _response.body as Speechall.TranscriptionResponse, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400: throw new Speechall.BadRequestError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 401: throw new Speechall.UnauthorizedError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 402: throw new Speechall.PaymentRequiredError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 404: throw new Speechall.NotFoundError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 429: throw new Speechall.TooManyRequestsError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 500: throw new Speechall.InternalServerError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 503: throw new Speechall.ServiceUnavailableError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 504: throw new Speechall.GatewayTimeoutError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                default: throw new errors.SpeechallError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.body,
                    rawResponse: _response.rawResponse
                });
            }
        }

        return handleNonStatusCodeError(_response.error, _response.rawResponse, "POST", "/transcribe");
    }

    /**
     * This endpoint allows you to transcribe an audio file hosted at a publicly accessible URL.
     * Provide the URL and transcription options within the JSON request body.
     * Useful for transcribing files already stored online.
     *
     * @param {Speechall.RemoteTranscriptionConfiguration} request
     * @param {SpeechToTextClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link Speechall.BadRequestError}
     * @throws {@link Speechall.UnauthorizedError}
     * @throws {@link Speechall.PaymentRequiredError}
     * @throws {@link Speechall.NotFoundError}
     * @throws {@link Speechall.TooManyRequestsError}
     * @throws {@link Speechall.InternalServerError}
     * @throws {@link Speechall.ServiceUnavailableError}
     * @throws {@link Speechall.GatewayTimeoutError}
     *
     * @example
     *     await client.speechToText.transcribeRemote({
     *         model: "openai.whisper-1",
     *         language: "en",
     *         output_format: "json",
     *         diarization: true,
     *         file_url: "https://example.com/path/to/audio.mp3"
     *     })
     */
    public transcribeRemote(request: Speechall.RemoteTranscriptionConfiguration, requestOptions?: SpeechToTextClient.RequestOptions): core.HttpResponsePromise<Speechall.TranscriptionResponse> {
        return core.HttpResponsePromise.fromPromise(this.__transcribeRemote(request, requestOptions));
    }

    private async __transcribeRemote(request: Speechall.RemoteTranscriptionConfiguration, requestOptions?: SpeechToTextClient.RequestOptions): Promise<core.WithRawResponse<Speechall.TranscriptionResponse>> {
        const _authRequest: core.AuthRequest = await this._options.authProvider.getAuthRequest();
        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(_authRequest.headers, this._options?.headers, requestOptions?.headers);
        const _response = await core.fetcher({
            url: core.url.join(await core.Supplier.get(this._options.baseUrl) ?? (await core.Supplier.get(this._options.environment) ?? environments.SpeechallEnvironment.Default), "transcribe-remote"),
            method: "POST",
            headers: _headers,
            contentType: "application/json",
            queryParameters: requestOptions?.queryParams,
            requestType: "json",
            body: request,
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 60) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging
        });
        if (_response.ok) {
            return { data: _response.body as Speechall.TranscriptionResponse, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400: throw new Speechall.BadRequestError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 401: throw new Speechall.UnauthorizedError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 402: throw new Speechall.PaymentRequiredError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 404: throw new Speechall.NotFoundError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 429: throw new Speechall.TooManyRequestsError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 500: throw new Speechall.InternalServerError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 503: throw new Speechall.ServiceUnavailableError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 504: throw new Speechall.GatewayTimeoutError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                default: throw new errors.SpeechallError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.body,
                    rawResponse: _response.rawResponse
                });
            }
        }

        return handleNonStatusCodeError(_response.error, _response.rawResponse, "POST", "/transcribe-remote");
    }

    /**
     * Returns a detailed list of all STT models accessible through the Speechall API.
     * Each model entry includes its identifier (`provider.model`), display name, description,
     * supported features (languages, formats, punctuation, diarization), and performance characteristics.
     * Use this endpoint to discover available models and their capabilities before making transcription requests.
     *
     * @param {SpeechToTextClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link Speechall.BadRequestError}
     * @throws {@link Speechall.UnauthorizedError}
     * @throws {@link Speechall.PaymentRequiredError}
     * @throws {@link Speechall.NotFoundError}
     * @throws {@link Speechall.TooManyRequestsError}
     * @throws {@link Speechall.InternalServerError}
     * @throws {@link Speechall.ServiceUnavailableError}
     * @throws {@link Speechall.GatewayTimeoutError}
     *
     * @example
     *     await client.speechToText.listSpeechToTextModels()
     */
    public listSpeechToTextModels(requestOptions?: SpeechToTextClient.RequestOptions): core.HttpResponsePromise<Speechall.SpeechToTextModel[]> {
        return core.HttpResponsePromise.fromPromise(this.__listSpeechToTextModels(requestOptions));
    }

    private async __listSpeechToTextModels(requestOptions?: SpeechToTextClient.RequestOptions): Promise<core.WithRawResponse<Speechall.SpeechToTextModel[]>> {
        const _authRequest: core.AuthRequest = await this._options.authProvider.getAuthRequest();
        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(_authRequest.headers, this._options?.headers, requestOptions?.headers);
        const _response = await core.fetcher({
            url: core.url.join(await core.Supplier.get(this._options.baseUrl) ?? (await core.Supplier.get(this._options.environment) ?? environments.SpeechallEnvironment.Default), "speech-to-text-models"),
            method: "GET",
            headers: _headers,
            queryParameters: requestOptions?.queryParams,
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 60) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging
        });
        if (_response.ok) {
            return { data: _response.body as Speechall.SpeechToTextModel[], rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400: throw new Speechall.BadRequestError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 401: throw new Speechall.UnauthorizedError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 402: throw new Speechall.PaymentRequiredError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 404: throw new Speechall.NotFoundError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 429: throw new Speechall.TooManyRequestsError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 500: throw new Speechall.InternalServerError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 503: throw new Speechall.ServiceUnavailableError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                case 504: throw new Speechall.GatewayTimeoutError(_response.error.body as Speechall.ErrorResponse, _response.rawResponse);
                default: throw new errors.SpeechallError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.body,
                    rawResponse: _response.rawResponse
                });
            }
        }

        return handleNonStatusCodeError(_response.error, _response.rawResponse, "GET", "/speech-to-text-models");
    }
}
